<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Junliang He (何俊亮)</title>

  <meta name="author" content="Junliang He">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="images/fudan_icon.jpg">

  <script type="text/javascript">

    function display(id) {
      var traget = document.getElementById(id);
      if (traget.style.display == "none") {
        traget.style.display = "";
      } else {
        traget.style.display = "none";
      }
    }  
  </script>
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Junliang He<img style="max-height:50px;vertical-align: middle;"
                        src="images/chinese_name.png" /></name>
                    <!-- <name>Tianxiang Sun <span style="color:black;font-size:22pt;font-family:STFangSong"><b>(孙天祥)</b></span><br/></name> -->
                  </p>
                  <p>I am a 1st-year M.S. student at the <a href="https://nlp.fudan.edu.cn/">NLP Lab</a> at <a
                      href="https://www.fudan.edu.cn/en/">Fudan University</a>. Before that, I received my B.Eng. from <a href="https://www.cqu.edu.cn">Chongqing
                      University</a> in 2022.
                  </p>
                  
                  <p style="text-align:center">
                    <a href="data/Tianxiang-CV.pdf">CV</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=puHFkM0AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/jlhe2000">Github</a> &nbsp/&nbsp
                    <a href="https://twitter.com/TianxiangSun">Twitter</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/SUN-Tianxiang">Zhihu</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/jlhe.jpeg"><img style="width:80%;max-width:80" alt="profile photo"
                      src="images/jlhe.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                      <li> <b>[Sep. 2022]</b> I joined the NLP Lab at Fudan University as a M.S. student.</li>
                      <li> <b>[Jun. 2022]</b> I received B.Eng. from College of Computer Science, Chongqing
                        University. GPA: 3.93/4.0 (top 0.1%)</li>
                    </div>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications (</heading><a href="https://txsun1997.github.io/papers"><heading>All Papers</heading></a><heading>)</heading>
                  <p>
                    <a href="https://scholar.google.com/citations?user=puHFkM0AAAAJ&hl=en">Google Scholar</a> /
                    <a href="https://www.semanticscholar.org/author/Tianxiang-Sun/153345698">Semantic Scholar</a> / <a
                      href="https://dblp.org/pid/254/1189.html">DBLP</a> / <a
                      href="https://orcid.org/my-orcid?orcid=0000-0001-8291-820X">ORCID</a>
                  </p>
                  <p>
                    (*: Equal contribution)
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/BBTICML2022.png' width="190">
                    </div>
                    <img src='images/BBTICML2022.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://proceedings.mlr.press/v162/sun22e.html">
                    <papertitle>Black-Box Tuning for Language-Model-as-a-Service</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Yunfan Shao, Hong Qian, Xuanjing Huang, Xipeng Qiu
                  <br>
                  <em>ICML</em>, 2022 &nbsp <font color="red"><strong>(Spotlight)</strong></font>
                  <br>
                  <a href="https://proceedings.mlr.press/v162/sun22e/sun22e.pdf">pdf</a>
                  /
                  <a href="https://github.com/txsun1997/Black-Box-Tuning">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/bbt.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a promising and practical scenario, Language-Model-as-a-Service (LMaaS), where users
                    cannot access model parameters and gradients but can only access language models' output
                    probability. For such a scenario, we propose the black-box tuning to optimize continuous prompts via
                    derivative-free optimization.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ParadigmShift.png' width="190">
                    </div>
                    <img src='images/ParadigmShift.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://link.springer.com/article/10.1007/s11633-022-1331-6">
                    <papertitle>Paradigm Shift in Natural Language Processing</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Xiangyang Liu, Xipeng Qiu, Xuanjing Huang
                  <br>
                  <em>Machine Intelligence Research</em>, 2022 &nbsp <font color="red"><strong>(Invited Paper)</strong>
                  </font>
                  <br>
                  <a href="https://link.springer.com/content/pdf/10.1007/s11633-022-1331-6.pdf">pdf</a>
                  /
                  <a href="https://txsun1997.github.io/nlp-paradigm-shift/">project</a>
                  /
                  <a href="https://txsun1997.github.io/slides/nlp-paradigm-shift.pdf">slides</a>
                  <p></p>
                  <p>
                    Recent years have witnessed a trend of paradigm shift in a variety of NLP tasks, which is to solve a
                    task that is originally performed with a paradigm (e.g., sequence labeling) with another paradigm
                    (e.g., machine reading comprehension).
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ElasticBERT.gif' width="190">
                    </div>
                    <img src='images/ElasticBERT.gif' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://aclanthology.org/2022.naacl-main.240/">
                    <papertitle>Towards Efficient NLP: A Standard Evaluation and A Strong Baseline</papertitle>
                  </a>
                  <br>
                  Xiangyang Liu*, <strong>Tianxiang Sun</strong>*, Junliang He, Jiawen Wu, Lingling Wu, Xinyu Zhang, Hao
                  Jiang, Zhao Cao, Xuanjing Huang, Xipeng Qiu
                  <br>
                  <em>NAACL</em>, 2022 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://aclanthology.org/2022.naacl-main.240.pdf">pdf</a>
                  /
                  <a href="https://github.com/fastnlp/ElasticBERT">code</a>
                  /
                  <a href="http://eluebenchmark.fastnlp.top/">benchmark</a>
                  /
                  <a href="https://txsun1997.github.io/slides/ELUE.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a benchmark, ELUE (Efficient Language Understanding Evaluation), for efficient NLP models
                    and a strong baseline/backbone pre-trained model, ElasticBERT.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/CoLAKE.png' width="190">
                    </div>
                    <img src='images/CoLAKE.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://aclanthology.org/2020.coling-main.327/">
                    <papertitle>CoLAKE: Contextualized Language and Knowledge Embedding</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>, Yunfan Shao, Xipeng Qiu, Qipeng Guo, Yaru Hu, Xuanjing Huang, Zheng
                  Zhang
                  <br>
                  <em>COLING</em>, 2020
                  <br>
                  <a href="https://aclanthology.org/2020.coling-main.327.pdf">pdf</a>
                  /
                  <a href="https://github.com/txsun1997/CoLAKE">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/CoLAKE.pdf">slides</a>
                  <p></p>
                  <p>
                    We pre-train a model called CoLAKE for jointly learning language and knowledge representation by
                    unifying language and knowledge into word-knowledge graphs.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/SesameStreet.jpg' width="190">
                    </div>
                    <img src='images/SesameStreet.jpg' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://link.springer.com/article/10.1007/s11431-020-1647-3">
                    <papertitle>Pre-trained Models for Natural Language Processing: A Survey</papertitle>
                  </a>
                  <br>
                  Xipeng Qiu, <strong>Tianxiang Sun</strong>, Yige Xu, Yunfan Shao, Ning Dai, Xuanjing Huang
                  <br>
                  <em>SCIENCE CHINA Technological Sciences</em>, 2020 &nbsp <font color="red"><strong>(Invited Paper,
                      Most Influential Paper of SCTS in 2020)</strong></font>
                  <br>
                  <a href="https://link.springer.com/content/pdf/10.1007/s11431-020-1647-3.pdf">pdf</a>
                  <p></p>
                  <p>
                    We provide a comprehensive survey of pre-trained models (PTMs) for NLP, ranging from non-contextual
                    word embeddings to state-of-the-art language models. This is a hands-on guide for understanding,
                    using, and developing PTMs for various NLP tasks.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/SparseSharing.png' width="190">
                    </div>
                    <img src='images/SparseSharing.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://ojs.aaai.org//index.php/AAAI/article/view/6424">
                    <papertitle>Learning Sparse Sharing Architectures for Multiple Tasks</papertitle>
                  </a>
                  <br>
                  <strong>Tianxiang Sun</strong>*, Yunfan Shao*, Xiaonan Li, Pengfei Liu, Hang Yan, Xipeng Qiu, Xuanjing
                  Huang
                  <br>
                  <em>AAAI</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://txsun1997.github.io/papers/aaai2020.pdf">pdf</a>
                  /
                  <a href="https://github.com/choosewhatulike/sparse-sharing">code</a>
                  /
                  <a href="https://txsun1997.github.io/slides/sparse_sharing.pdf">slides</a>
                  <p></p>
                  <p>
                    We propose a new parameter sharing mechanism for multi-task learning, sparse sharing, which
                    allocates a subnet for a task based on lottery ticket hypothesis. The sparse sharing successfully
                    avoids negative transfer between tasks.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Resources</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/LMaaS.png' width="190">
                    </div>
                    <img src='images/LMaaS.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://github.com/txsun1997/LMaaS-Papers">
                    <papertitle>Paper List on Language-Model-as-a-Service (LMaaS)</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong>
                  <p>
                    Pre-trained large language models (LLMs) such as GPT-3 are usually released as a service instead of
                    open sourcing model weights. We call this scenario "Language-Model-as-a-Service (LMaaS)", where
                    users can access the powerful LLMs through their inference APIs. We maintain a curated list of
                    papers that fit into this scenario.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ELUE.png' width="190">
                    </div>
                    <img src='images/ELUE.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="http://eluebenchmark.fastnlp.top/">
                    <papertitle>ELUE: A Multi-dimensional Benchmark for Efficient NLP Methods</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong> and <a
                    href="https://scholar.google.com/citations?hl=en&user=U8QD9mwAAAAJ">Xiangyang Liu</a>
                  <p>
                    ELUE (Efficient Language Understanding Evaluation) is a standard benchmark for evaluating and
                    comparing performance, FLOPs, and number of parameters of efficient NLP models such as compressed
                    models and early exiting models.
                  </p>
                </td>
              </tr>

              <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='malle_image'>
                      <img src='images/ParadigmShiftPj.png' width="190">
                    </div>
                    <img src='images/ParadigmShiftPj.png' width="190">
                  </div>
                  <script type="text/javascript">
                    function malle_start() {
                      document.getElementById('malle_image').style.opacity = "1";
                    }

                    function malle_stop() {
                      document.getElementById('malle_image').style.opacity = "0";
                    }
                    malle_stop()
                  </script>
                </td>
                <td style="padding:20px;width:70%;vertical-align:top">
                  <a href="https://txsun1997.github.io/nlp-paradigm-shift/">
                    <papertitle>Paradigm Shift in Natural Language Processing</papertitle>
                  </a>
                  <br>
                  maintained by <strong>Tianxiang Sun</strong>
                  <p>
                    A paradigm is a general modeling framework or a distinct set of methodologies to solve a class of
                    tasks. For example, sequence labeling is a mainstream paradigm for named entity recognition (NER).
                    Recent years have witnessed a rising trend of paradigm shift, which is solving a task in a new
                    paradigm by reformulating the task.
                  </p>
                </td>
              </tr>

            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>
                  <p>
                    I serve as a reviewer or program committee member of several top-tier NLP/ML/AI conferences.
                  </p>
                  <ul>
                    <li> <b>ACL</b>: 2021, 2022</li>
                    <li> <b>EMNLP</b>: 2021, 2022</li>
                    <li> <b>COLING</b>: 2020, 2022</li>
                    <li> <b>ICML</b>: 2022</li>
                    <li> <b>NeurIPS</b>: 2022</li>
                    <li> <b>AAAI</b>: 2021, 2022</li>
                    <li> <b>IJCAI</b>: 2021, 2022</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Awards</heading>
                  <ul>
                    <li> National Scholarship for Graduate Student, Oct. 2020</li>
                    <li> Outstanding Graduate of Xidian University, Jun. 2019</li>
                    <li> Honorable Mention in MCM/ICM, Feb. 2018</li>
                    <li> First Prize in National MCM (Shaanxi division), Oct. 2017</li>
                    <li> Principal Scholarship in School of Computer Science and Technology at XDU (4 times), 2017-2019
                    </li>
                    <li> First Prize Scholarship of Xidian University (4 times), 2015-2019</li>
                    <li> First Prize in China High School Biology Olympiad, Jun. 2014</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:30%;vertical-align:middle">
                  <script type='text/javascript' id='clustrmaps'
                    src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=m&d=aBj-4SCzZBu24IVENbl19cAetpLjEP1RCaSORs6c7A8'></script>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's
                    website</a>
                </p>
              </td>
            </tr>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>